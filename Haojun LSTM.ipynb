{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Style Transfer through LSTM\n",
    "\n",
    "Here we are attempting to see whether we can transfer the style of the music by changing the notes themselves. Here, our definition of style transfer has changed. We are interested in seeing whether a network can generate music by being \"inspired\" from another music.\n",
    "\n",
    "To do this, we will first train a CNN that classifies music well. Then, we will use the actiavtions from one of the layers as a feature extractor and extract features from music. \n",
    "\n",
    "Next step is to use the features we extracted to generate the music back. This is done by conditioning a (possibly bidirectional) LSTM using the feature vector, and then train it to generate the music that was used to extract the feature vector. We will train 2 such generators.\n",
    "\n",
    "Last step is to see whether the generators works as a translator. We will take one music from one class and extract the features. And then feed the feature into the other class to generate music. We will see if the network picks up the styles and whether the network can be \"inspired\" by the music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mido\n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn.model_selection as ms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Here we will load the data that was already preprocessed. We will do some final stitching to make it usable for our algorithms. One of the thing we realized is that the files are different sizes. So in order for CNN to work they must be the same size. So what we will do is just simply pad them with 0s so it will not affect training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classical_matrices = np.load('matricies/classical_matrices.npy')\n",
    "jazz_matrices = np.load('matricies/jazz_matrices.npy')\n",
    "classical_infos = np.load('matricies/classical_infos.npy')\n",
    "jazz_infos = np.load('matricies/jazz_infos.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([x.shape[0] for x in classical_matrices])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10195, 130, 2)\n"
     ]
    }
   ],
   "source": [
    "## Here we pad every array to be of size 5000\n",
    "T = 5000\n",
    "for i in range(len(classical_matrices)):\n",
    "    m = classical_matrices[i]\n",
    "    if m.shape[0] > T:\n",
    "        classical_matrices[i] = m[:T, :, :]\n",
    "    else:\n",
    "        classical_matrices[i] = np.pad(m, ((0, T - m.shape[0]), (0, 0), (0, 0)), 'constant', constant_values=(0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(jazz_matrices)):\n",
    "    m = jazz_matrices[i]\n",
    "    if m.shape[0] > T:\n",
    "        jazz_matrices[i] = m[:T, :, :]\n",
    "    else:\n",
    "        jazz_matrices[i] = np.pad(m, ((0, T - m.shape[0]), (0, 0), (0, 0)), 'constant', constant_values=(0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.stack(classical_matrices)\n",
    "X2 = np.stack(jazz_matrices)\n",
    "X = np.concatenate((X1, X2), axis=0)\n",
    "Y1 = np.ones(len(classical_matrices))\n",
    "Y2 = np.zeros(len(jazz_matrices))\n",
    "Y = np.concatenate((Y1, Y2))\n",
    "Y = Y.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(698, 5000, 130, 2)\n",
      "(698, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to stack the last 2 layers since we will look at them at the same time anyways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(698, 5000, 260)\n"
     ]
    }
   ],
   "source": [
    "X3 = np.concatenate((X[:,:,:,0], X[:,:,:,1]), axis=-1)\n",
    "print(X3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('matricies/newX.npy', X3)\n",
    "np.save('matricies/newY.npy', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('matricies/newX.npy')\n",
    "Y = np.load('matricies/newY.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(698, 5000, 260)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(558, 5000, 260) (140, 5000, 260) (558, 1) (140, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = ms.train_test_split(X, Y, test_size=0.2, random_state=123)\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN encoding\n",
    "\n",
    "In this section we first try to train a CNN that classifies music well. Here we will use a simple structure of\n",
    "\n",
    "1. Conv\n",
    "2. Dense\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(input_shape):\n",
    "    X_input = keras.layers.Input(input_shape)\n",
    "    X = X_input\n",
    "    X = keras.layers.Conv1D(filters=10, kernel_size=50, padding='same', name='Conv0',\n",
    "                            dilation_rate=8,\n",
    "                            kernel_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "                            bias_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "                            data_format=\"channels_last\")(X)\n",
    "    X = keras.layers.AveragePooling1D(20)(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 2, name = 'bn0')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    print(X.shape)\n",
    "    \n",
    "#     X = keras.layers.Reshape((250, -1))(X)\n",
    "    X = keras.layers.Conv1D(filters=40, kernel_size=20, padding='valid', name='Conv1',\n",
    "                            dilation_rate=4,\n",
    "                            kernel_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "                            bias_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "                            data_format=\"channels_last\")(X)\n",
    "    X = keras.layers.AveragePooling1D(20)(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 2, name = 'bn1')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    print(X.shape)\n",
    "    X = keras.layers.Flatten()(X)\n",
    "#     X = keras.layers.Dense(100, activation='sigmoid')(X)\n",
    "#     X = keras.layers.Dropout(0.5)(X)    \n",
    "    X = keras.layers.Dense(50, activation='sigmoid')(X)\n",
    "    X = keras.layers.Dropout(0.5)(X)    \n",
    "    X = keras.layers.Dense(10, activation='sigmoid')(X)\n",
    "    X = keras.layers.Dense(1, activation='sigmoid')(X)\n",
    "    model = keras.models.Model(inputs=X_input, outputs=X, name='basic')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 250, 10)\n",
      "(?, 8, 40)\n"
     ]
    }
   ],
   "source": [
    "m = model1(X.shape[1:])\n",
    "m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_47 (InputLayer)        (None, 5000, 260)         0         \n",
      "_________________________________________________________________\n",
      "Conv0 (Conv1D)               (None, 5000, 10)          130010    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_20 (Averag (None, 250, 10)           0         \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 250, 10)           40        \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 250, 10)           0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv1D)               (None, 174, 40)           8040      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_21 (Averag (None, 8, 40)             0         \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 8, 40)             160       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 8, 40)             0         \n",
      "_________________________________________________________________\n",
      "flatten_36 (Flatten)         (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 50)                16050     \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 154,821\n",
      "Trainable params: 154,721\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "m.fit(X_train, Y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM \n",
    "\n",
    "Here we will train 2 (bidirectional) LSTMs. One for generating classical music and one for generating jazz music. The way we condition the LSTMs is to have a Dense layer that transforms our feature vectors into the shape of the cell state of the LSTM, and then we will use this cell state as the initial cell state of the LSTM, and train it to generate the original MIDI matrix. \n",
    "\n",
    "The input to the model is a feature vector. It will then have a dense layer that transforms it into the cell state shape. Then for every time stamp it will generate some music, and the output should be a music.\n",
    "\n",
    "First we need to construct the new X and Ys. The X will be the same but with the last layer stacked on top of each other insead. Y will be the same as X but all values shifted left by 1 timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2 = np.zeros(X.shape, dtype=np.int32)\n",
    "Y2[:-1,:,:] = X[1:,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is inspired and borrowed from Coursera Sequence Model Module/Improvise a Jazz Solo with an LSTM Network - v3 programming assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 64\n",
    "n_values = Y.shape[-1]\n",
    "LSTM_cell = keras.layers.LSTM(n_a, return_state = True)\n",
    "densor = keras.layers.Dense(n_values, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(feature_shape, Tx, n_channel):\n",
    "    feature_input = keras.layers.Input(feature_shape)\n",
    "    music_input = keras.layers.Input((Tx, n_channel))\n",
    "    a0 = keras.layers.Input((n_a,), name='a0')\n",
    "    \n",
    "    feature_input = keras.layers.Flatten()(feature_input)\n",
    "    c0 = keras.layers.Dense(n_a)(feature_input)\n",
    "    \n",
    "    X = music_input\n",
    "    a = a0\n",
    "    c = c0\n",
    "    outputs = []\n",
    "    for t in range(Tx):\n",
    "        if t % 1000 == 0:\n",
    "            print(t)\n",
    "        x = keras.layers.Lambda(lambda x: X[:, t, :])(X)\n",
    "        x = keras.layers.Reshape((1, n_channel))(x)\n",
    "        a, _, c = LSTM_cell(x, initial_state=[a, c])\n",
    "        out = densor(a)\n",
    "        outputs += [out]\n",
    "    return keras.models.Model(inputs=[feature_input, music_input, a0], outputs=outputs)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-f22b17b66f46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binary_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-173-f5082bba551a>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(feature_shape, Tx, n_channel)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_channel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0moriginal_input_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   2192\u001b[0m                                       \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2193\u001b[0m                                       \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2194\u001b[0;31m                                       initial_state=initial_state)\n\u001b[0m\u001b[1;32m   2195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2196\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[1;32m    647\u001b[0m                                              \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                                              \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m                                              input_length=timesteps)\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length)\u001b[0m\n\u001b[1;32m   2920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2921\u001b[0m         \u001b[0mtime_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2922\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2923\u001b[0m         output_ta = tensor_array_ops.TensorArray(\n\u001b[1;32m   2924\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(inputs, states)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         last_output, outputs, states = K.rnn(step,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, states, training)\u001b[0m\n\u001b[1;32m   1973\u001b[0m                                                       self.recurrent_kernel_i))\n\u001b[1;32m   1974\u001b[0m             f = self.recurrent_activation(x_f + K.dot(h_tm1_f,\n\u001b[0;32m-> 1975\u001b[0;31m                                                       self.recurrent_kernel_f))\n\u001b[0m\u001b[1;32m   1976\u001b[0m             c = f * c_tm1 + i * self.activation(x_c + K.dot(h_tm1_c,\n\u001b[1;32m   1977\u001b[0m                                                             self.recurrent_kernel_c))\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/activations.py\u001b[0m in \u001b[0;36mhard_sigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;36m0.2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2.5\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2.5\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \"\"\"\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhard_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mhard_sigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   3408\u001b[0m     \u001b[0mzero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3409\u001b[0m     \u001b[0mone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3410\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3411\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/clip_ops.py\u001b[0m in \u001b[0;36mclip_by_value\u001b[0;34m(t, clip_value_min, clip_value_max, name)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# Go through list of tensors, for each value in each tensor clip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mt_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_value_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;31m# Assert that the shape is compatible with the initial shape,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# to prevent unintentional broadcasting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mminimum\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   4917\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4918\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 4919\u001b[0;31m         \"Minimum\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m   4920\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4921\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_ref\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m         \u001b[0moutput_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model((500, 1), 1000, X.shape[2])\n",
    "m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
