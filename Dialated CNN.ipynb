{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizing Velocity Prediction with CNN\n",
    "\n",
    "This part of the notebook attempts to realize the velocity prediction with CNN as opposed to the LSTM models used in the original [paper](https://arxiv.org/pdf/1708.03535.pdf). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mido\n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn.model_selection as ms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 Loading and processing data (DEPRECATED)\n",
    "\n",
    "In this part we would first process the data into a form that we can use. We will be reusing code from the [GitHub repo](https://github.com/imalikshake/StyleNet) of the paper author to process the data the way he did it.\n",
    "\n",
    "First, we use the code to convert it into the format that they provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"TPD/classical/bach_846_format0.mid\"\n",
    "midi = mido.MidiFile(fpath)\n",
    "midi_array, velocity_array = midi_util.midi_to_array_one_hot(midi, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we inspect the data that we loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"midi_array shape = %s\" % str(midi_array.shape)\n",
    "print \"velocity_array shape = %s\" % str(velocity_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we attempt to divide up the midi_array into 2 layers, so the data would be a volumn instead of a 1d array. This may allow us to learn better features through convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_notes = midi_array[:, ::2]\n",
    "midi_continuation = midi_array[:, 1::2]\n",
    "X = np.dstack((midi_notes, midi_continuation))\n",
    "print \"X shape = %s\" % str(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be generalized to loading and converting an entire subset of music files. The code to do that is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_midis(base_fpath):\n",
    "    fpaths = []\n",
    "    for (root, dirnames, filenames) in os.walk(base_fpath):\n",
    "        fpaths += [os.path.join(root, filename) for filename in filenames]\n",
    "    return [mido.MidiFile(fpath) for fpath in fpaths]\n",
    "\n",
    "def convert_midis(midis):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for midi in midis:\n",
    "        try:\n",
    "            midi_array, velocity_array = midi_util.midi_to_array_one_hot(midi, 4)\n",
    "        except:\n",
    "            continue\n",
    "        midi_notes = midi_array[:, ::2]\n",
    "        midi_continuation = midi_array[:, 1::2]\n",
    "        X_i = np.dstack((midi_notes, midi_continuation))\n",
    "        if (X_i.shape[0] > 1000):\n",
    "            X += [X_i]\n",
    "            Y += [velocity_array]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = convert_midis(load_midis(\"TPD/classical\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X's length is 150\n",
      "X[0]'s shape is (2048, 88, 2)\n",
      "Y's length is 150\n",
      "Y[0]'s shape is (2048, 88)\n"
     ]
    }
   ],
   "source": [
    "print \"X's length is %s\" % str(len(X))\n",
    "print \"X[0]'s shape is %s\" % str(X[0].shape)\n",
    "print \"Y's length is %s\" % str(len(Y))\n",
    "print \"Y[0]'s shape is %s\" % str(Y[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can store these matricies and load them later so we don't loose them. Note that the shapes of these matricies are not what we intended and needs further processing. The X matrix contains 183 3D matricies but it iself is not a 4D matrix because each matrix within it does not have the same dimention. In order to solve this problem we need to either pad the songs so that they are the same time, or end songs early and only take a sample from the song so we can make the matricies the same dimension. \n",
    "\n",
    "So now we will see the minimum size of the songs and take a sample of the same size from every song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum shape of songs is (1024, 88, 2)\n",
      "Now the sizes of the matricies are X: (150, 1024, 88, 2), Y: (150, 1024, 88)\n"
     ]
    }
   ],
   "source": [
    "print \"Minimum shape of songs is %s\" % str(min(X, key=lambda x: x.shape[0]).shape)\n",
    "\n",
    "min_shape_X, _, _ = min(X, key=lambda x: x.shape[0]).shape\n",
    "new_X = []\n",
    "for X_i in X:\n",
    "    new_X += [X_i[:min_shape_X, :, :]]\n",
    "new_X = np.stack(new_X)\n",
    "\n",
    "new_Y = []\n",
    "for Y_i in Y:\n",
    "    new_Y += [Y_i[:min_shape_X, :]]\n",
    "new_Y = np.stack(new_Y)\n",
    "print \"Now the sizes of the matricies are X: %s, Y: %s\"% (str(new_X.shape), str(new_Y.shape))\n",
    "\n",
    "X, Y = new_X, new_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.expand_dims(Y, axis=3)\n",
    "np.save(\"matricies/X.npy\", X)\n",
    "np.save(\"matricies/Y.npy\", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"matricies/X.npy\")\n",
    "Y = np.load(\"matricies/Y.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Modeling\n",
    "Now we have represented our data, we would like to see if we can build a model that predicts the velocities through the 3D matrix we generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('matricies/notes.npy')\n",
    "Y = np.load('matricies/velocities.npy')\n",
    "labels = np.load('matricies/labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_classical = X[(labels == 1).ravel()]\n",
    "Y_classical = Y[(labels == 1).ravel()]\n",
    "# X_classical = X_classical[:,:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3750, 480, 59, 2) (417, 480, 59, 2) (3750, 480, 59) (417, 480, 59)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = ms.train_test_split(X_classical, Y_classical, test_size=0.1, random_state=43)\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Attempt to use a CNN of filter size (100, 1)\n",
    "\n",
    "First we will try to use a CNN of filter size (100, 1) and see if we can correctly fit the velocity data.\n",
    "The code block below will split the dataset into train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(input_shape):\n",
    "    X_input = keras.layers.Input(input_shape)\n",
    "    X_on_off = keras.layers.Lambda(lambda X:X[:,:,:,0])(X_input)\n",
    "    X_sustain = keras.layers.Lambda(lambda X:X[:,:,:,1])(X_input)\n",
    "    X = X_sustain\n",
    "    X = keras.layers.ZeroPadding1D((185, 0))(X)\n",
    "    X = keras.layers.Conv1D(filters=input_shape[-2], kernel_size=64, dilation_rate=1, name='Conv0',\n",
    "                            kernel_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "                            bias_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "                            data_format=\"channels_last\")(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 2, name = 'bn0')(X)\n",
    "    X = keras.layers.Conv1D(filters=input_shape[-2], kernel_size=32, dilation_rate=2, padding='valid', name='Conv1',\n",
    "                            kernel_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "                            bias_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "                            data_format=\"channels_last\")(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 2, name = 'bn1')(X)\n",
    "    X = keras.layers.Conv1D(filters=input_shape[-2], kernel_size=16, dilation_rate=4, padding='valid', name='Conv2',\n",
    "                            kernel_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "                            bias_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "                            data_format=\"channels_last\")(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 2, name = 'bn2')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    print(X.shape)\n",
    "    print(X_on_off.shape)\n",
    "    X = keras.layers.Multiply()([X, X_on_off])\n",
    "#     X = keras.layers.Flatten()(X)\n",
    "    model = keras.models.Model(inputs=X_input, outputs=X, name='basic')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 480, 59)\n",
      "(?, 480, 59)\n"
     ]
    }
   ],
   "source": [
    "m1 = model1(input_shape=X_train.shape[1:])\n",
    "m1.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3750/3750 [==============================] - 32s 8ms/step - loss: 5.4927 - acc: 0.9205\n",
      "Epoch 2/100\n",
      "3750/3750 [==============================] - 32s 8ms/step - loss: 5.3163 - acc: 0.9209\n",
      "Epoch 3/100\n",
      "3750/3750 [==============================] - 32s 8ms/step - loss: 5.0848 - acc: 0.9220\n",
      "Epoch 4/100\n",
      "3750/3750 [==============================] - 32s 9ms/step - loss: 4.9132 - acc: 0.9223\n",
      "Epoch 5/100\n",
      "3750/3750 [==============================] - 33s 9ms/step - loss: 4.7705 - acc: 0.9234\n",
      "Epoch 6/100\n",
      "3750/3750 [==============================] - 35s 9ms/step - loss: 4.6467 - acc: 0.9238\n",
      "Epoch 7/100\n",
      "3750/3750 [==============================] - 35s 9ms/step - loss: 4.4905 - acc: 0.9242\n",
      "Epoch 8/100\n",
      "3750/3750 [==============================] - 35s 9ms/step - loss: 4.3912 - acc: 0.9248\n",
      "Epoch 9/100\n",
      "3750/3750 [==============================] - 35s 9ms/step - loss: 4.2990 - acc: 0.9256\n",
      "Epoch 10/100\n",
      "3750/3750 [==============================] - 35s 9ms/step - loss: 4.1768 - acc: 0.9261\n",
      "Epoch 11/100\n",
      "3750/3750 [==============================] - 35s 9ms/step - loss: 4.0659 - acc: 0.9266\n",
      "Epoch 12/100\n",
      "3750/3750 [==============================] - 35s 9ms/step - loss: 3.9841 - acc: 0.9271\n",
      "Epoch 13/100\n",
      "3750/3750 [==============================] - 35s 9ms/step - loss: 3.9478 - acc: 0.9272\n",
      "Epoch 14/100\n",
      "3750/3750 [==============================] - 35s 9ms/step - loss: 3.8637 - acc: 0.9282\n",
      "Epoch 15/100\n",
      "3750/3750 [==============================] - 35s 9ms/step - loss: 3.7904 - acc: 0.9281\n",
      "Epoch 16/100\n",
      "3750/3750 [==============================] - 35s 9ms/step - loss: 3.7066 - acc: 0.9290\n",
      "Epoch 17/100\n",
      "3750/3750 [==============================] - 37s 10ms/step - loss: 3.6279 - acc: 0.9293\n",
      "Epoch 18/100\n",
      "3750/3750 [==============================] - 37s 10ms/step - loss: 3.6187 - acc: 0.9292\n",
      "Epoch 19/100\n",
      "3750/3750 [==============================] - 37s 10ms/step - loss: 3.5532 - acc: 0.9299\n",
      "Epoch 20/100\n",
      "3750/3750 [==============================] - 37s 10ms/step - loss: 3.5145 - acc: 0.9296\n",
      "Epoch 21/100\n",
      "3200/3750 [========================>.....] - ETA: 5s - loss: 3.4685 - acc: 0.9300- ETA: 9s - loss: 3.442 - ETA: 7s - loss: 3.4633 - ac"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-185acbd258ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Run multiple times to train further!\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\haojun\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\haojun\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\haojun\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\haojun\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\haojun\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m1.fit(X_train, Y_train, epochs = 100, batch_size=16) # Run multiple times to train further!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.save('m1_conv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = keras.models.load_model('m1_conv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - 2s 4ms/step\n",
      "Loss = 3.4842131572375767\n",
      "Test Accuracy = 0.9354266584348335\n"
     ]
    }
   ],
   "source": [
    "preds = m1.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_0_hat = m1.predict(np.expand_dims(X_test[0], axis=0))\n",
    "Y_0_hat = Y_0_hat.reshape(-1, X_test.shape[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 59)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_0_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x288b2511908>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 14400x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (200,10))\n",
    "plt.imshow(Y_0_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x288b24c0b38>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAG4AAAJCCAYAAAAhqvKfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGUZJREFUeJztnXuQVNWdx78/QccEg0CCLPIcsMcHsIiAvFJWghsXkqyQMnGlLKU2lFQqJpVUqM2yZe1ayS5VJinWVCyTLCzWasrFpXSNbBJRA6YsFXFAUBiRmYHhMYEFsgEMZIMiv/1jbuPt7jt9+94+9/Gb/n6qprrvo889M585fc8595zfEVUFscdFWWeAxIPijEJxRqE4o1CcUSjOKImIE5F5IrJHRDpFZHkS12h0xHU7TkT6AWgH8BkA3QBaASxS1bedXqjBSaLE3QigU1X3qep7AJ4AsCCB6zQ0/RNIcwSAQ77tbgAzqn3g0kGX6iWnPhr5Qs1/fhpdb10W+XOXTzgHADjV1r9kn3+7yEeuBf5vd+RLxOYPOPE7VR0adl4S4iRgX8X3sYgsBbAUAC7FRzFDbo5+pZ3AFUFXC6P4pS1l+4LSeqeX/Qnxa33yQC3nJfFV2Q1glG97JIDD5Sep6ipVnaaq0y5GUwLZ6NskIa4VQEFEmkXkEgB3AFifwHUaGudflap6TkS+BuA5AP0APKKqba6v0+gk0o5T1V+paouqjlfVFUlcwxWjtwwo2R62eWDgeXN3nkkjOzXT8D0nB2eUCjk6693A8zZNGhC4PysaXpxVKM4oFGeUhhQ3cdtFmLit9Fcf8FJwZ8UX3j6eRpYik0TPSe7ZNfV8xb4zNwULevq60N6nTGjIEtcXoDijUJxRGk7c6Q3jSraP/PzainPKKy55JP85dMxl8/aVbA9fWPmwLajykjcaTtzsN98r2W7/6Y0l2xZKG9CA4l6dfEnJdstXXi/ZtlDagAYUVwtL2ruyzkIoFBfAmpbmrLMQCsUZheKMQnFGoTiHpNmUaDhxJ++eVbK9d+XM0HNqpdiUmN92Mtbno+B87kAcBsoQjTUg1gATt10UqW34a31ym6pOCzuv4Upc2uyaeh737dvhPF2KCyCo47me4Xkrxl0PwO3TdIoLIKjj2cXwvOLT9PL+0jhQnFEoLgOKHd2F1iYUWuNNeGnIwUJ5oWP6WQA9I8x6G6zUGw1f4oLmCrSvnl6xr3yOgUuiSgMoLnCuQMs9rRX7yucYZE3Di7MKxRmF4mqE8+OIEygugKDHM/6ek3s72tPMTiAUF0BYb/7DhZaUctI7FGcUijMKxRmF4gJIsnvLFQ0vLuihad66t4JoOHHlDemgh6YWaDhxfYWGE5e3CEFxyZW4A9+NNp6xa+3kyNcoH+/R/dSEinMszNbhuMqcwXGVfRyKMwrFGaUhxZ3eMK4ibEZQJQXoPfBo1jSkuL5AQ46rLI91AgAjbwsOG91bxNisYYkzCsUZJRfizjZHX54FiNdzcn7jqJLt4+uvrjin34tXxspPmrDnJGew56SPQ3FGoTijUJxRGlJc1wOz0PVA6bO/3sLX57XLqyF7TpqXb67Y19vkQvacEKdQnFEozigUF8DZ58dmnYVQGk7cgXWTSrbLa5cA0HTL/pRyE5+GE9dXaDhxY27fWbId1DSwQMOJ6ytQnFEozigNI679kQ+fTR5YN6midgkEx2fOKw3TV9ny5a0X3pdXUICesZbj572WZpbqomFKXFAJ8xM0ZC/PNIy4oFJmmYYR19egOKOYE3fw/tmxPtfv2sKF9/tXzML+FZV9lL1N/MgjHFeZMziuso9DcUahOKNQnFEozigUZxSKM0pDiut47AZ0PHZDxf4TvywEnJ1PGkacf72cwt1voHD3GxXnDP5cR5pZqouGERe0Xo4rFr1zOLG0e6NhxCXJ2mt65oynsRpxEYpzyLMTBgFws5RmGBSXAMUVGZOE4oxCcQkTtE6PCxpSXG/tuPaf3lixLyiATRR2TT2fyBJmfJCaIrPffC/0/scHqTmkKM1Fs4HiMuDZCYPqbjJQXAj+oesuZ6r6vzLj3AN5j8sZvMf1cSjOKBRnFIozCsUZJVSciDwiIsdEZJdv3xAReUFEOrzXwd5+EZEfiUiniLwlIpX9SsQJtZS4fwcwr2zfcgAbVbUAYKO3DQDzARS8n6UAfuImm9nR8dCMwPd+/G29tKipHSciYwH8QlUnett7AHxKVY+IyHAAv1HVq0XkX733a8vPq5Y+23EfknQ7blhRhvd6hbd/BIBDvvO6vX0ViMhSEdkqIlvfx9mY2WhcXFdOJGBfYJFW1VWqOk1Vp12MJsfZ6PvEFXfU+4qE93rM298NwL8iw0gA6Q+BagDiilsPYLH3fjGAZ3z77/ZqlzMBnAq7v5F4hMY5EZG1AD4F4BMi0g3gfgAPAFgnIksAHATwJe/0XwH4LIBOAH8E8DcJ5JmgBnGquqiXQxXVQO2pot5bb6ZIOOw5MQrFGYXijEJxRqE4o1CcUSjOKBRnFIozCsUZheKMQnFGoTijUJxRKM4oDSnu4P2zA2M7H1lWuS8odnM5pzeMc5KvKHCaVc7gNKsMSHNgLMU5xL9+T9JQXAKkUfIozigUlwD+r8x6A9z0BsUlzNBb9yTSXKA4H/u+X9lm80+tav9xZcioWiiuTde1dnK8jAXAdlzOYDsux7hYNYviMmDkbW0YvWVAXWlQXEYcnPFhGKg4NU+KywFDb90T+TMUZxSKi0BQcwGo7dGPa9gcyBlsDvRxKM4oFGcUijMKxRmF4oxCcUahOKNQnFEozigUZxSKS4D/+WblHATXUFwE/vRXwYOF+hVKR3H92Q9fTTwvFBeBS//79cD9H3TsSzknFGcWijMKxRmF4oxCcUahOKNQnFEozigUZxSKMwrFGYXijEJxRqE4o1CcUSjOKBRnFIozCsUZheKMQnFGoTijUJxRKM4oFGcUijMKxRmF4nwERS9vXz39wvs/fmFGxXEAmLgt/T8jQ0I55PSGcRfC+MaFIaEyoCht7+NTEr8WxSXA+Du3X3jf78UrE7kGxYXgX/Wqt7CHwzYP7PXzH3z6MJa0dznPF+9xKTLgpaE4c9PxqufwHpdDitLqDaQNUJxZKC4DDs44g7k7z4SfWAWKi8CpO2fWdN7U7edDz9k06cOvy7PPj42cF4qLwOWPv1bTedumRPuzNt2yP3JeKM4oFGcUijMKxTngZ4deqet4HCjOKBTngLtGzanreBwozigUZxSKMwrFJcCidw6ja+1kp6sQl9M/sZQbkInbLsKuqeex9por0Yw3E70WS5xDdk0N71x2BcUZheKMQnE+Oh67oerxWpd9nt920kV2qsLBQjmDg4UyZn7byURLHpsDCfHshEGJps8S56P7qQlVj89+871Y6S5653Csz1WD97ic4eweJyKjRORFEdktIm0i8g1v/xAReUFEOrzXwd5+EZEfiUiniLwlItWran2QNGqVtXxVngOwTFWvBTATwL0ich2A5QA2qmoBwEZvGwDmAyh4P0sB/MR5rkm4OFU9oqpveO//AGA3gBEAFgB41DvtUQALvfcLADymPbwGYJCIDHee8xyTdMUEiFg5EZGxAKYA2AJgmKoeAXrkArjCO20EgEO+j3V7+8rTWioiW0Vk6/s4Gz3nOWfY5oFVZ/HUS83NARG5DMBTAL6pqu+KSK+nBuyrqAGp6ioAq4Ceykmt+bDC0VnvJpp+TSVORC5Gj7THVfW/vN1Hi1+B3usxb383gFG+j48E4L4+nEMGvDQ0tWvVUqsUAGsA7FbVf/EdWg9gsfd+MYBnfPvv9mqXMwGcKn6l9nXC5r65pJYSNwfAXQDmisgO7+ezAB4A8BkR6QDwGW8bAH4FYB+ATgCrAXzVfbbzRdyGeT2E3uNU9WUE37cAoKLVrD0t+nvrzJcpXp18SerXZJeXUSjOKBRnFIozCsU5IKxTefXBl51fk+IcENY3ec/oTzq/JsUZheKMQnEJsKS9C4XWJhRamxK7BsUZhaO8EmBNSzOQ8DNGljiH1BJRyBUU55CoEYXqgeJ8hI2rrPVBqYuwhmFQnI+Rt7VVPV7rg9KDM85g6vbziX51snKSEEl/bbLEGYXifJz4ZaHq8aCI5kd+fm1oukl8ZVKcUTjpI2dwYmNO+MLbyQzZo7iEefq6ZAbJUlwKsHJilCTadBSXIi5HPFNcirgc8UxxRqG4FEgi6gLFpcDaa9wv/kdxRqE4o1BcBIrLRmexfHQ52efAEMUIsGlGgu0NijMKxRmF4oxCcUahuBRIYgF3ikuBnrkEwL0d7c7SpLgUebjQ4iwtisuAhw7Uv4Ijxfk4sG5SKtf5+pj6FwKkOB9jbt+Z2rXqvd9RnFEoLiPqrahQXAYs6yydzhWnskJxEShO8Ni/YlZd6ay8qnQCZZzKCsVFYPjC3QCAsfdtzjgnFGcWijMKxWVEvcMfKC4j6h3+QHFGoTijUJxRKM5HWGShpJi780zkz1Ccj7DIQkmxaVL0EFIUZxSKMwrFRaB99XQAwN6VMzPOCcWZheIi0HJPKwBg/LLXMs4JxZmF4oxCcUahOKNQnFEozigU5yOtIejlxAl3T3FGoTgfac4d8HNwBh/rNAwUZxSKi0DX2skAgPZHQoOUhxK0hkEUGL4+ZzB8fR+H4oxCcUahuBRo//GNVY/HiY5OcSnQ8tXXqx6PEx2d4oxCcT5cdTLv+374VOPBrwyp6xpsx+UMtuP6OBRnFIozCsUZheIcsPfxKVWP11uDDILiHDD+zu1Vj5+Y83vn16Q4o1BcQpzfOArnN45KLP3+iaXcwBRam9Ax/VCi12CJc0gxWlDH9LOJX4viHJLmYkkUZxSKMwrF+SgOv+uN4+uvrimdYZsHushOVSjOR/OiN6seH3rrnprSOTrrXRRam1BobXKRrUDYHEiIpGuWLHEpEGcwUBgU5yMsunmt97hy4gwGCoPifIRFN6/1HhcnGl5UKC4B4kTDiwrFGSVUnIhcKiKvi8ibItImIt/x9jeLyBYR6RCR/xSRS7z9Td52p3d8bLK/Qj6Z33YS89tOJpZ+LSXuLIC5qjoZwPUA5onITADfA/CgqhYAnACwxDt/CYATqnoVgAe98xoCf7vt2QmD8OyEQYldK1Sc9nDa27zY+1EAcwE86e1/FMBC7/0Cbxve8ZtFRJzlOMek8VSgSE33OBHpJyI7ABwD8AKAvQBOquo575RuACO89yMAHAIA7/gpAB93mWlSozhV/UBVrwcwEsCNAK4NOs17DSpdFcOlRWSpiGwVka3vI73/1CSYuj29xzlFItUqVfUkgN8AmAlgkIgUu8xGAjjsve8GMAoAvOOXA6gYLaOqq1R1mqpOuxjJ9emlwbYp6VfOa6lVDhWRQd77jwD4CwC7AbwI4IveaYsBPOO9X+9twzu+SfMwQaGPUUsn83AAj4pIP/SIXqeqvxCRtwE8ISL/DGA7gDXe+WsA/ExEOtFT0u5IIN8NT6g4VX0LQMWIT1Xdh577Xfn+PwH4kpPckV5hz4lRKM4BHQ/NqHo8iVonxTmg8PUtVY8nUeukOKNQXEKM3jIgVgDRWuGYkwSYuv08tk1J9mEqS5xDBrw0FEA6PSkUZxSKc8iZm46ndi2K89H1QPVRXkd+HvRQpJLTG8a5yE5VGKAmZzBATcac3jAu0ZLH5kBCXDZvX6Lps8T5OPDd8OBp5dRy36s3cHYQFOdjzD9WH8ks0yuj6w1fuDs03Q8+fTj0nKhQnFEoLgLaGn0Jl6T6KykuYeKsm1MLFJcCxTAaLqG4FEgijAbFpcjZ58c6S4viUqTplv3O0qK4FOA9zii8x5ELUJxRKC4G7aunZ50FiotCcURyyz2tGeeE4iKRxTy43shPTkgkKM4oFJcCS9q7nKdJcUahuBRY09LsPE2KSxGXX5kUlyIuSx7F+UirR+SfuupvwFOcj7R6RP6huf5/EIrLiPv27ajr8xSXESvGXV/X5ykuAsV1wtt/WhGXJxKL3ikd2fzQgVcip0FxRuH8uJzB+XF9HIozCsUZheIyImzJszAoLiPCljwLg+KMQnFGoTgfWY2XjLO+HMX5yGq8ZJz15SjOKBRnFIqLwN6VM0tes4TiIjB+2Wslr1lCcUahOKNQnFEozigUZxSKMwrFGYXifLQ/EjpGJxHirHZFcT5avrw1k+vGmVtOcUahOKNQnFEoLgLFUPUdj91Qd1r1xq7kEPScwSHofRyKywFxVgKhuBQ4eP/sqsfjrARCcSkw+juvOk+T4oxCcUahuIw4v3FUXZ+nOB/1Tsovcvjb1SsjAHDRzYfqugbF+Wj5yutO0rny++4rI+VQnFEozigUF4F7O9oBJLeYXxQoLgIPF1oAJLeYXxQozigUZxSKMwrFOaA8Gl69sShrgeIcsPaa0udp9cairAWKSwEXMZjLoTgfg18ZUvX46Q3jak7rB/tfww/298xcdRGDuZz+zlM0zIk5v696/LJ5+6oen7r9/IVRyX87Ntl54ixxDgkbSr6ss83ZtSjOKBSXIiuvmuAsLYrzEdZ5PGzzwJrTmrr9fMX0qfW/dVe7pDgfYZ3HR2e9W3Na26ZcdOGe1/1UT0m7dYS72iXFJcDcnaX/AB984P7PTHEJsGlS6VfumNt3Or8GxTmgvK9yXffmxK9JcQ4o76u8feSsxK9JcUahuBRgJ7NRkuhkpjgfYQ3wsOP+B6j+pwNJUPNUYhHpB2ArgN+q6udFpBnAEwCGAHgDwF2q+p6INAF4DMBUAP8L4K9VdX+1tBtlKvHqgy/jntGfrHpOElOJvwFgt2/7ewAeVNUCgBMAlnj7lwA4oapXAXjQO48AodKiUJM4ERkJ4HMA/s3bFgBzATzpnfIogIXe+wXeNrzjN3vn556wSAhRpvw+d3gHnjtcOvbEZSWl1gepPwTwbQAf87Y/DuCkqp7ztrsBjPDejwBwCABU9ZyInPLO/52THCdI0y37qx6PMuX3L6+sHHfispISWuJE5PMAjqnqNv/ugFO1hmP+dJeKyFYR2fo+ztaUWSssae8q2U6iklJLiZsD4FYR+SyASwEMRE8JHCQi/b1SNxJA8d+xG8AoAN0i0h/A5QAqxgSo6ioAq4Ceykm9v0ijEVriVPXvVXWkqo4FcAeATap6J4AXAXzRO20xgGe89+u9bXjHN2keouCkyJqW5pLtJMaf1NOO+zsA3xKRTvTcw9Z4+9cA+Li3/1sAlteXxfyz+uDLJdsuH5j2BkNCpcDPDr2Cu0bNqelchoTKEbVKiwLFGYXifISNZA5rgPubAcs625yOoyyH97gUWdbZFjpEj/e4Pg7FpQgHxCbEgXWTqh6PEnnovn07KiY4lg8qqgfe43IG73EZUgy6XSTOSh5hUFwCDF+4u2Q7zkoeYVBcApQ/kJ3fdtL5NSguAcofyD47YZDza1CcY46vv7pku321+6F5AMWZheIcM/TWPSXbLfck82yO4nyEfa2FNtB9CweO3jIg0fCIbIDnDDbA+zgUF4MBLw3NOgsUF4W9j08BAJy56XjGOaG4SIy/c3vWWbgAxRmF4oxCcUahuAwoRhoqEmehW4rLgJG3lQ7bC5veFQTFGYXijEJxPsJGcYV1MkdlwEtDY/fCsJM5Z7CTuY9DcUahOKNQnI9Td1afq71/RfLhDGuF4nxc/nj1sBZj70smgGickc4UlwPijHSmuBxQHtCmFiguAzoeu6FkuzwuSi1QnFEoLgMKd79RdxoUZxSK8xFlqnDWUJyPlq+8XvV4x0MznF6vf/MY9G8eE++zTnPSxyl8fYvT9M51HYj9WZY4o1Ccj7B7XNcD7KvMJWH3uOblyS92VCsUZxSKywH+CZG1QnE5oOXLWyN/huIyoPz5W5wYXxSXAeXP38oXDqwFijMKxfk4dN/sVK4zcVv9f3aK8zFqxatVjx9Z5kbsrqml97iwWNBBUJxRKC4Cw1dWL5FxOTGnYumhUCjOKBTnY+/K6gNiXT+PKxIndBRn6+QMztbJOXFqkn4oLiPiVEj8UFxG1BsPjOIyot54YBRnFIrLgBO/LNSdBsVlwODPddSdBsX5CAuHUR6avh661k6u6/NsgOcMNsD7OBRnFIrzETZSOc4wuqSgOKNQnI+wIeZxxj8mBcUZheKMQnEOOL1hXMl2GiuBUJwDLpu3r2S7vOc/TrDsMCguBeIEyw6D4nzU247zRwwatnkghm0e6CRfQbCvMmewr7KPQ3Ep4nLpTYpLkYMzzjhLi+J8hIXujRIyqtDahEJrU8m+OJFgeyMXlRMROQ7gDIDfZZ2XBPkEavv9xqhqaAs+F+IAQES21lKbsorr349flUahOKPkSdyqrDOQME5/v9zc40g08lTiSAQyFyci80Rkj4h0isjyrPPjChHZLyI7RWSHiGz19g0RkRdEpMN7HRw3/UzFiUg/AA8DmA/gOgCLROS6LPPkmE+r6vW+ZsByABtVtQBgo7cdi6xL3I0AOlV1n6q+B+AJAAsyzlOSLADwqPf+UQAL4yaUtbgRAA75tru9fX0BBfC8iGwTkaXevmGqegQAvNcr4iaedTBtCdjXV6q5c1T1sIhcAeAFEXnHZeJZl7huAKN82yMBRI8BmENU9bD3egzA0+i5LRwVkeEA4L0ei5t+1uJaARREpFlELgFwB4D1GeepbkRkgIh8rPgewC0AdqHnd1vsnbYYwDNxr5HpV6WqnhORrwF4DkA/AI+oalvIxywwDMDTIgL0/I3/Q1U3iEgrgHUisgTAQQBfinsB9pwYJeuvShITijMKxRmF4oxCcUahOKNQnFEozij/D+adXLXspwZyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 14400x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (200,10))\n",
    "plt.imshow(Y_test[0].reshape(-1, X_test.shape[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
