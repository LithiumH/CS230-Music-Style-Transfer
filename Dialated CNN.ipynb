{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizing Velocity Prediction with CNN\n",
    "\n",
    "This part of the notebook attempts to realize the velocity prediction with CNN as opposed to the LSTM models used in the original [paper](https://arxiv.org/pdf/1708.03535.pdf). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named mido",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4b5ca0e90679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmido\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStyleNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmidi_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmidi_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named mido"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mido\n",
    "import keras\n",
    "import numpy as np\n",
    "import StyleNet.midi_util as midi_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 Loading and processing data\n",
    "\n",
    "In this part we would first process the data into a form that we can use. We will be reusing code from the [GitHub repo](https://github.com/imalikshake/StyleNet) of the paper author to process the data the way he did it.\n",
    "\n",
    "First, we use the code to convert it into the format that they provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mido' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4570bf388a71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"TPD/classical/bach_846_format0.mid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmidi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmido\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMidiFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmidi_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvelocity_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmidi_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmidi_to_array_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mido' is not defined"
     ]
    }
   ],
   "source": [
    "fpath = \"TPD/classical/bach_846_format0.mid\"\n",
    "midi = mido.MidiFile(fpath)\n",
    "midi_array, velocity_array = midi_util.midi_to_array_one_hot(midi, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we inspect the data that we loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"midi_array shape = %s\" % str(midi_array.shape)\n",
    "print \"velocity_array shape = %s\" % str(velocity_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we attempt to divide up the midi_array into 2 layers, so the data would be a volumn instead of a 1d array. This may allow us to learn better features through convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_notes = midi_array[:, ::2]\n",
    "midi_continuation = midi_array[:, 1::2]\n",
    "X = np.dstack((midi_notes, midi_continuation))\n",
    "print \"X shape = %s\" % str(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be generalized to loading and converting an entire subset of music files. The code to do that is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_midis(base_fpath):\n",
    "    fpaths = []\n",
    "    for (root, dirnames, filenames) in os.walk(base_fpath):\n",
    "        fpaths += [os.path.join(root, filename) for filename in filenames]\n",
    "    return [mido.MidiFile(fpath) for fpath in fpaths]\n",
    "\n",
    "def convert_midis(midis):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for midi in midis:\n",
    "        print \"size of X is %d\" % len(X)\n",
    "        try:\n",
    "            midi_array, velocity_array = midi_util.midi_to_array_one_hot(midi, 4)\n",
    "        except:\n",
    "            continue\n",
    "        midi_notes = midi_array[:, ::2]\n",
    "        midi_continuation = midi_array[:, 1::2]\n",
    "        X_i = np.dstack((midi_notes, midi_continuation))\n",
    "        X += [X_i]\n",
    "        Y += [velocity_array]\n",
    "    return np.stack(X), np.stack(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = convert_midis(load_midis(\"TPD/classical\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X's shape is (183,)\n",
      "X[0]'s shape is (2048, 88, 2)\n",
      "Y's shape is (183,)\n",
      "Y[0]'s shape is (2048, 88)\n"
     ]
    }
   ],
   "source": [
    "print \"X's shape is %s\" % str(X.shape)\n",
    "print \"X[0]'s shape is %s\" % str(X[0].shape)\n",
    "print \"Y's shape is %s\" % str(Y.shape)\n",
    "print \"Y[0]'s shape is %s\" % str(Y[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can store these matricies and load them later so we don't loose them. Note that the shapes of these matricies are not what we intended and needs further processing. The X matrix contains 183 3D matricies but it iself is not a 4D matrix because each matrix within it does not have the same dimention. In order to solve this problem we need to either pad the songs so that they are the same time, or end songs early and only take a sample from the song so we can make the matricies the same dimension. This will be explored later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"matricies/X.npy\", X)\n",
    "np.save(\"matricies/Y.npy\", X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Modeling\n",
    "Now we have represented our data, we would like to see if we can build a model that predicts the velocities through the 3D matrix we generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Attempt to use a CNN of filter size (100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_shape):\n",
    "    X_input = keras.layers.Input(input_shape)\n",
    "    X = keras.layers.Conv2D(filters=50, kernel_size=(100, 1), strides=(1, 1), padding='same', name='Conv0')(X_input)\n",
    "#     X = keras.layers.BatchNormalization(axis = 2, name = 'bn0')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    \n",
    "#     X = keras.layers.Conv2D(filters=3, kernel_size=(1, 88), strides=(1, 1), padding='same', name='Conv1')(X_input)\n",
    "#     X = BatchNormalization(axis = 3, name = 'bn1')(X)\n",
    "#     X = Activation('relu')(X)\n",
    "    \n",
    "    X = keras.layers.Conv2D(filters=1, kernel_size=(100, 1), strides=(1, 1), padding='same', name='Conv1')(X_input)\n",
    "    model = keras.models.Model(inputs=X_input, outputs=X, name='basic')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model((None, 88, 2))\n",
    "m.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(X[0], Y, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Attempt to use CNN and filter size (100, 88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.matrix(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 88, 2)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
